## 🧠 Feuille de Route Python pour la Data (2025)

### 🌟 Objectif :  
Devenir **autonome en manipulation, analyse, visualisation et traitement de données** avec Python — avec des bases solides pour évoluer vers la data science, l’ingénierie de la donnée ou l’IA.

---

## 📂 Structure du programme

### 🔹 Phase 1 – Fondamentaux Python (2 à 3 semaines)

**Compétences visées :**
- Syntaxe Python, logique, structures de données
- Fonctions, modules, fichiers
- Bonne pratique de code (PEP8, organisation)

**Ressources :**
- [Documentation Python Officielle](https://docs.python.org/fr/3/)
- [Apprendre Python – OpenClassrooms](https://openclassrooms.com/fr/courses/6204541-initiez-vous-a-python)
- [Real Python Beginner’s Guide](https://realpython.com/start-here/)

**À faire :**
- 📝 Mini-projets : générateur de mot de passe, convertisseur de devises, jeu de devinette.

---

### 🔹 Phase 2 – Manipulation de données avec Pandas & Numpy (3 semaines)

**Compétences visées :**
- Chargement, nettoyage, filtrage, groupement de données
- Calculs vectorisés avec NumPy
- Gestion des types, des dates, des valeurs manquantes

**Ressources :**
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Numpy Handbook](https://numpy.org/doc/)
- [Kaggle: Python & Pandas Courses](https://www.kaggle.com/learn)

**Projets suggérés :**
- Analyse de CSV publics (climat, finances, transports)
- Tableau de bord synthétique avec résumé statistique

---

### 🔹 Phase 3 – Visualisation de données (2 semaines)

**Compétences visées :**
- Graphiques avec Matplotlib & Seaborn
- Visualisation interactive avec Plotly

**Ressources :**
- [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html)
- [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)
- [Plotly Express](https://plotly.com/python/plotly-express/)

**Mini-projets :**
- Analyse visuelle d’un dataset
- Dashboard Jupyter

---

### 🔹 Phase 4 – SQL & Bases de données (1-2 semaines)

**Compétences visées :**
- Requêtes SQL : SELECT, JOIN, GROUP BY…
- Connexion SQL avec Python (sqlite3, SQLAlchemy)
- Requêtes sur de grands jeux de données

**Ressources :**
- [SQL pour la Data Science – Mode d'emploi](https://mode.com/sql-tutorial/)
- [Kaggle SQL Course](https://www.kaggle.com/learn/advanced-sql)

---

### 🔹 Phase 5 – Data Cleaning & Feature Engineering (2 semaines)

**Compétences visées :**
- Nettoyage de données (doublons, formats, valeurs aberrantes)
- Transformation & enrichissement des variables
- Pipelines de traitement

**Ressources :**
- [Data Cleaning with Pandas](https://realpython.com/python-data-cleaning-numpy-pandas/)
- [Feature Engineering Book (Hands-On)](https://www.feature-engineering-book.com/)

---

### 🔹 Phase 6 – Initiation à la Data Science (facultatif ou après projet) (3-4 semaines)

**Compétences visées :**
- Scikit-learn : régression, classification, clustering
- Préparation des données
- Évaluation de modèles

**Ressources :**
- [Scikit-learn documentation](https://scikit-learn.org/stable/)
- [Cours IA de Google](https://developers.google.com/machine-learning/crash-course)
- [Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)

---

### 🔹 Phase 7 – Portfolio & GitHub (en continu)

**Objectif :**
- Publier ton code proprement documenté sur GitHub
- Inclure README, captures, structure de dossier claire
- Héberger les notebooks ou les transformer en scripts reproductibles

**Projets possibles :**
- Dashboard météo ou transport
- Comparaison de performances entre deux datasets
- Exploration d’un dataset public (IMDb, OpenFoodFacts, Airbnb…)

---

## 🔧 Stack utilisée

- Python 3.11+
- JupyterLab / VSCode
- Pandas, NumPy, Matplotlib, Seaborn, Plotly
- SQLite / PostgreSQL
- Git, GitHub
- En option : Poetry ou Pipenv, Makefile, Docker

---

## 📌 Conseils pratiques

- Ne saute pas les fondamentaux Python
- Note tout ce que tu apprends (Notion, Obsidian, GitHub)
- Refais plusieurs fois les mêmes manipulations pour ancrer
- Participe à des compétitions Kaggle dès la phase 2
- Publie 2 à 3 projets concrets sur GitHub

